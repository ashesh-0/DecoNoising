{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from unet.model import UNet\n",
    "from deconoising.utils import PSNR\n",
    "from deconoising import utils\n",
    "from deconoising import prediction\n",
    "\n",
    "# See if we can use a GPU\n",
    "device=utils.getDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the training data in order to calulate 'mean' and 'std' for normalization\n",
    "fpath='/mnt/ashesh/Flywing/Flywing_n10/test/test_data.npz'\n",
    "# Load the test data\n",
    "data_dict = np.load(fpath)\n",
    "X_test = data_dict['X_test']\n",
    "# X_train = data_dict['X_train']\n",
    "# X_val = data_dict['X_val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deconoising.synthetic_data_generator import PSFspecify, create_dataset\n",
    "from deconoising.training import artificial_psf\n",
    "\n",
    "pixel_independent_gaussian_noise_std = None\n",
    "psf_list = [PSFspecify(81,3)]\n",
    "psf_tensor_list = [artificial_psf(psf.size, psf.std) for psf in psf_list]\n",
    "convolvedGT = create_dataset(torch.Tensor(X_test[:,None]), psf_list, \n",
    "                             pixel_independent_gaussian_noise_std=pixel_independent_gaussian_noise_std).numpy()[:,0]\n",
    "noisyGT =X_test\n",
    "# dataTest =convolved_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "ax[0].imshow(convolvedGT[0][100:200,100:200])\n",
    "ax[1].imshow(X_test[0][100:200,100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Network\n",
    "Ensure that ```dataName``` is set same as in ```Convallaria-Training.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls /home/ubuntu/ashesh/data/Flywing/Flywing_n10/train/best*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network, created in the 'Convallaria-Training.ipynb' notebook\n",
    "# capablerutherford-02aa4/home/ubuntu/ashesh/\n",
    "net = torch.load(f\"/home/ubuntu/ashesh/training/deconoising/2305/N2V_N4_1.0-5.0/1/best_model.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "im = convolvedGT[index]\n",
    "deconvolvedResult, denoisedResult = prediction.tiledPredict(im, net[3] ,ps=256, \n",
    "                                                            overlap=48, \n",
    "                                                            device=device,\n",
    "                                                            psf_list=psf_tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_sz = 64\n",
    "h = np.random.randint(im.shape[0] - crop_sz)\n",
    "w = np.random.randint(im.shape[1] - crop_sz)\n",
    "print(h,w,crop_sz)\n",
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(im[h:h+crop_sz,w:w+crop_sz])\n",
    "if denoisedResult is not None:\n",
    "    ax[1].imshow(denoisedResult[h:h+crop_sz,w:w+crop_sz])\n",
    "\n",
    "ax[2].imshow(noisyGT[index][h:h+crop_sz,w:w+crop_sz])\n",
    "ax[3].imshow(deconvolvedResult[h:h+crop_sz,w:w+crop_sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are processing data and calculating PSNR values.\n",
    "\n",
    "psnr_input = []\n",
    "psnrNoisyGT_denoised_prediction = []\n",
    "psnrNoisyGT_denoised_deconvolved_prediction = []\n",
    "psnrConvolvedGT_denoised_prediction = []\n",
    "psnrConvolvedGT_denoised_deconvolved_prediction = []\n",
    "\n",
    "# We iterate over all test images.\n",
    "for index in range(convolvedGT.shape[0]):\n",
    "    \n",
    "    im = convolvedGT[index]\n",
    "    \n",
    "    # We are using tiling to fit the image into memory\n",
    "    # If you get an error try a smaller patch size (ps)\n",
    "    # Here we are predicting the deconvolved and denoised image\n",
    "    deconvolvedResult, denoisedResult = prediction.tiledPredict(im, net[0] ,ps=256, overlap=48, device=device,\n",
    "                                                                psf_list=psf_tensor_list)\n",
    "    \n",
    "    # calculate PSNR\n",
    "    gt = noisyGT[index]\n",
    "    rangePSNR = np.max(gt) - np.min(gt)\n",
    "    psnr_input.append(PSNR(gt, im, rangePSNR)) \n",
    "\n",
    "\n",
    "    if denoisedResult is not None:\n",
    "        psnrNoisyGT_denoised_prediction.append(PSNR(gt, denoisedResult, rangePSNR))\n",
    "    psnrNoisyGT_denoised_deconvolved_prediction.append(PSNR(gt, deconvolvedResult, rangePSNR))\n",
    "    \n",
    "    gt = convolvedGT[index]\n",
    "    rangePSNR = np.max(gt) - np.min(gt)\n",
    "    if denoisedResult is not None:\n",
    "        psnrConvolvedGT_denoised_prediction.append(PSNR(gt, denoisedResult, rangePSNR))\n",
    "    psnrConvolvedGT_denoised_deconvolved_prediction.append(PSNR(gt, deconvolvedResult, rangePSNR))\n",
    "\n",
    "\n",
    "print(\"Avg PSNR input:\", np.mean(np.array(psnr_input)).round(2),  '+-(2SEM)', (2*np.std(np.array(psnr_input))/np.sqrt(float(len(psnr_input)))).round(2))\n",
    "if denoisedResult is not None:\n",
    "    print(\"[NoisyGT]: Avg PSNR denoised\", np.mean(np.array(psnrNoisyGT_denoised_prediction)).round(2),  \n",
    "          '+-(2SEM)', (2*np.std(np.array(psnrNoisyGT_denoised_prediction))/np.sqrt(float(len(psnrNoisyGT_denoised_prediction)))).round(2))\n",
    "print(\"[NoisyGT]: Avg PSNR denoised & deconvolved\", np.mean(np.array(psnrNoisyGT_denoised_deconvolved_prediction)).round(2),  \n",
    "      '+-(2SEM)', (2*np.std(np.array(psnrNoisyGT_denoised_deconvolved_prediction))/np.sqrt(float(len(psnrNoisyGT_denoised_deconvolved_prediction)))).round(2))\n",
    "\n",
    "if denoisedResult is not None:\n",
    "    print(\"[ConvolvedGT]: Avg PSNR denoised\", np.mean(np.array(psnrConvolvedGT_denoised_prediction)).round(2),  \n",
    "          '+-(2SEM)', (2*np.std(np.array(psnrConvolvedGT_denoised_prediction))/np.sqrt(float(len(psnrConvolvedGT_denoised_prediction)))).round(2))\n",
    "print(\"[ConvolvedGT]: Avg PSNR denoised & deconvolved\", np.mean(np.array(psnrConvolvedGT_denoised_deconvolved_prediction)).round(2),  \n",
    "      '+-(2SEM)', (2*np.std(np.array(psnrConvolvedGT_denoised_deconvolved_prediction))/np.sqrt(float(len(psnrConvolvedGT_denoised_deconvolved_prediction)))).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /home/ubuntu/ashesh/training/deconoising/2304/N2V_N5_3.0-5.0/6/log.out | grep tensor\\( | awk -F \",\" '{print $1}'| awk -F \"(\" '{print $2}' > temp.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.plot(np.loadtxt('temp.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the results for the last test image       \n",
    "vmi=np.percentile(gt,0.01)\n",
    "vma=np.percentile(gt,99)\n",
    "\n",
    "if denoisedResult is not None:\n",
    "    plt.imshow(denoisedResult[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input image')\n",
    "plt.imshow(im, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Deconv. output')\n",
    "plt.imshow(deconvolvedResult, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Denoised output')\n",
    "if denoisedResult is not None:\n",
    "    plt.imshow(denoisedResult, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input image')\n",
    "plt.imshow(im[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Deconv. output')\n",
    "plt.imshow(deconvolvedResult[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Denoised output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable Gaussian Layer\n",
    "The model is able to come to the correct PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deconoising.learnable_gaussian_blur import GaussianLayer\n",
    "import torch.nn as nn\n",
    "\n",
    "gblur = GaussianLayer(1,21,pad_type='reflect',std=10)\n",
    "\n",
    "index = 0\n",
    "inp = noisyGT[index][100:164,100:164].copy()\n",
    "tar = convolvedGT[index][100:164,100:164].copy()\n",
    "\n",
    "inp = torch.Tensor(inp[None,None])\n",
    "tar = torch.Tensor(tar[None,None])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = gblur(inp).cpu().numpy()\n",
    "\n",
    "_,ax = plt.subplots(figsize=(12,4),ncols=3)\n",
    "ax[0].imshow(inp[0,0])\n",
    "ax[1].imshow(out[0,0])\n",
    "ax[2].imshow(tar[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(gblur.parameters(), lr=0.1)\n",
    "for _ in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = gblur(inp)\n",
    "    loss = nn.MSELoss()(out[0,0], tar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"{loss.item():.2f} {gblur.std.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Disentangle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4503c4d8aea86af6f5d256c8ed00bb52b62a982b46ffc9d51ceb2666b8455c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
