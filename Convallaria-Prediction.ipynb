{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prediction\n",
    "Please run the ```Convallaria-Training.ipynb``` before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from unet.model import UNet\n",
    "from deconoising.utils import PSNR\n",
    "from deconoising import utils\n",
    "from deconoising import prediction\n",
    "\n",
    "# See if we can use a GPU\n",
    "device=utils.getDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the training data in order to calulate 'mean' and 'std' for normalization\n",
    "fpath='/home/ubuntu/ashesh/data/Flywing/Flywing_n10/test/test_data.npz'\n",
    "# Load the test data\n",
    "data_dict = np.load(fpath)\n",
    "X_test = data_dict['X_test']\n",
    "# X_train = data_dict['X_train']\n",
    "# X_val = data_dict['X_val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deconoising.synthetic_data_generator import PSFspecify, create_dataset\n",
    "\n",
    "psf_list = [PSFspecify(81,1)]\n",
    "convolved_data = create_dataset(torch.Tensor(X_test[:,None]), psf_list).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Network\n",
    "Ensure that ```dataName``` is set same as in ```Convallaria-Training.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network, created in the 'Convallaria-Training.ipynb' notebook\n",
    "net = torch.load(f\"/home/ubuntu/ashesh/data/Flywing/Flywing_n10/train/best_N2V.net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest =convolved_data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "im = dataTest[index]\n",
    "deconvolvedResult, denoisedResult = tiledPredict(im, net ,ps=256, overlap=48, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(X_test[0,100:200,100:200])\n",
    "ax[1].imshow(X_test[20,100:200,100:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_sz = 64\n",
    "h = np.random.randint(im.shape[0] - crop_sz)\n",
    "w = np.random.randint(im.shape[1] - crop_sz)\n",
    "print(h,w,crop_sz)\n",
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(im[h:h+crop_sz,w:w+crop_sz])\n",
    "if denoisedResult is not None:\n",
    "    ax[1].imshow(denoisedResult[h:h+crop_sz,w:w+crop_sz])\n",
    "\n",
    "ax[2].imshow(X_test[index][h:h+crop_sz,w:w+crop_sz])\n",
    "ax[3].imshow(deconvolvedResult[h:h+crop_sz,w:w+crop_sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are processing data and calculating PSNR values.\n",
    "\n",
    "psnr_result = []\n",
    "psnr_input = []\n",
    "\n",
    "# We iterate over all test images.\n",
    "for index in range(dataTest.shape[0]):\n",
    "    \n",
    "    im = dataTest[index]\n",
    "    \n",
    "    # We are using tiling to fit the image into memory\n",
    "    # If you get an error try a smaller patch size (ps)\n",
    "    # Here we are predicting the deconvolved and denoised image\n",
    "    deconvolvedResult, denoisedResult = tiledPredict(im, net ,ps=256, overlap=48, device=device)\n",
    "    \n",
    "    gt = dataTestGT[0] # The ground truth is the same for all images\n",
    "    # calculate PSNR\n",
    "    rangePSNR = np.max(gt) - np.min(gt)\n",
    "    psnr_result.append(PSNR(gt, denoisedResult, rangePSNR))\n",
    "    psnr_input.append(PSNR(gt, im, rangePSNR)) \n",
    "    print (\"image:\", index)\n",
    "    print (\"PSNR input\", PSNR(gt, im, rangePSNR))\n",
    "    print (\"PSNR denoised\", PSNR(gt, denoisedResult, rangePSNR)) \n",
    "    print ('-----------------------------------')\n",
    "    \n",
    "# We display the results for the last test image       \n",
    "vmi=np.percentile(gt,0.01)\n",
    "vma=np.percentile(gt,99)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input image')\n",
    "plt.imshow(im, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Deconv. output')\n",
    "plt.imshow(deconvolvedResult, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Denoised output')\n",
    "plt.imshow(denoisedResult, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input image')\n",
    "plt.imshow(im[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Deconv. output')\n",
    "plt.imshow(deconvolvedResult[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Denoised output')\n",
    "plt.imshow(denoisedResult[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "print(\"Avg PSNR input:\", np.mean(np.array(psnr_input)),  '+-(2SEM)', 2*np.std(np.array(psnr_input))/np.sqrt(float(len(psnr_input))))\n",
    "print(\"Avg PSNR denoised:\", np.mean(np.array(psnr_result)),  '+-(2SEM)', 2*np.std(np.array(psnr_result))/np.sqrt(float(len(psnr_result))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Disentangle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "068447a931bb4d6daeb83e04642366c1566a738715bf5337ac3a4c0e721de6b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
